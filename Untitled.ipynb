{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_json(r'H:\\Uni Docs\\Third Semester\\Data Science Lab\\Code\\Dataset\\Final_Chai\\Final All\\migrantPhase3Final_ALL.json', lines=\"True\", orient=\"records\", encoding=\"utf8\")\n",
    "#df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter, defaultdict\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenisation\n",
    "import re,nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['text']=df['text'].apply(lambda row: (re.sub(r'((RT @[^ ]+)|(http[^ ]*)|([—–])|([!”#$%&\\’\\'\\€\\✡\"\\‘()*+\\“,-\\.\\/:;<=>?@[\\]^_`{|}~…])|(([^A-Za-z0-9 ])))','', row, flags=re.IGNORECASE)))\n",
    "\n",
    "df['cleanedtext']=df['text'].apply(lambda row: (re.sub(r'([0-9]+)','c2a0f1s9', row, flags=re.IGNORECASE)))\n",
    "\n",
    "df['tokenised'] = df['cleanedtext'].apply(lambda row: nltk.word_tokenize(row.lower()))   \n",
    "\n",
    "#len(df['tokenised'])\n",
    "#df['tokenised'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopwords Removal\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "'theyre', 'thats', 'its'\n",
    "stop.append('theyre')\n",
    "stop.append('thats')\n",
    "stop.append('its')\n",
    "df['stopwords']=df['tokenised'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "df['stemmed']=df.apply(lambda row: [ps.stem(word) for word in row['tokenised']], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['stemmed'] \n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a Word2Vec model\n",
    "import gensim\n",
    "# Here X is list of tokenized texts (i.e. list of lists of tokens)\n",
    "model = gensim.models.Word2Vec(X, size=100, window=5, min_count=1, workers=2)\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)} #Words and corresponding vectors are stored as Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method For Word2Vec Model that uses mean as aggregation function\n",
    "class MeanAggrFunc(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        if len(word2vec)>0:\n",
    "            self.dim=len(word2vec[next(iter(w2v))])\n",
    "        else:\n",
    "            self.dim=0\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method for TFIDF Word2Vec Model\n",
    "class Tfidfw2vFunc(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        if len(word2vec)>0:\n",
    "            self.dim=len(word2vec[next(iter(w2v))])\n",
    "        else:\n",
    "            self.dim=0\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf, \n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifiers with Tf-idf features\n",
    "svc_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(ngram_range=(1, 2), stop_words='english',max_df=0.50, min_df=1,analyzer=lambda x: x)), (\"svc_tfidf\", SVC(kernel=\"linear\"))])\n",
    "percept_tfidf =  Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(ngram_range=(1, 2), stop_words='english',max_df=0.50, min_df=1,analyzer=lambda x: x)), (\"Percept_tfidf\", Perceptron(max_iter=5))])\n",
    "etree_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(ngram_range=(1, 2), stop_words='english',max_df=0.50, min_df=1,analyzer=lambda x: x)), (\"etree_tfidf\", ExtraTreesClassifier(n_estimators=200))])\n",
    "rand_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(ngram_range=(1, 2), stop_words='english',max_df=0.50, min_df=1,analyzer=lambda x: x)), (\"rand_tfidf\", RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifiers with Word2Vec features\n",
    "etree_w2v = Pipeline([\n",
    "    (\"word2vec vectorizer\", MeanAggrFunc(w2v)),\n",
    "    (\"etree_w2v\", ExtraTreesClassifier(n_estimators=200))])\n",
    "\n",
    "rand_w2v = Pipeline([\n",
    "    (\"word2vec vectorizer\", MeanAggrFunc(w2v)),\n",
    "    (\"rand_w2v\", RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifiers with combination of Tf-idf and Word2Vec features\n",
    "etree_combo = Pipeline([\n",
    "    (\"word2vec vectorizer\", Tfidfw2vFunc(w2v)),\n",
    "    (\"etree_combo\", ExtraTreesClassifier(n_estimators=200))])\n",
    "\n",
    "rand_combo = Pipeline([\n",
    "    (\"word2vec vectorizer\", Tfidfw2vFunc(w2v)),\n",
    "    (\"rand_combo\", RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Set = [\n",
    "    (\"svc_tfidf\", svc_tfidf),\n",
    "    (\"Percept_tfidf\", percept_tfidf),\n",
    "    (\"etree_tfidf\", etree_tfidf),\n",
    "    (\"rand_tfidf\",rand_tfidf),\n",
    "    (\"etree_w2v\", etree_w2v),\n",
    "    (\"rand_w2v\",rand_w2v),\n",
    "    (\"etree_combo\", etree_combo),\n",
    "    (\"rand_combo\",rand_combo),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evalaution of models using k-fold Cross validation\n",
    "result_accuracy = [(name, cross_val_score(model, X, y,scoring='accuracy', cv=10).mean()) for name, model in Model_Set]\n",
    "result_precision =[(name, cross_val_score(model, X, y,scoring='precision', cv=10).mean()) for name, model in Model_Set]\n",
    "result_recall = [(name, cross_val_score(model, X, y,scoring='recall', cv=10).mean()) for name, model in Model_Set]\n",
    "result_f1 = [(name, cross_val_score(model, X, y,scoring='f1', cv=10).mean()) for name, model in Model_Set]\n",
    "\n",
    "print (tabulate(result_accuracy, floatfmt=\".4f\", headers=(\"model\", 'Accuracy')))\n",
    "print (tabulate(result_precision, floatfmt=\".4f\", headers=(\"model\", 'Precision')))\n",
    "print (tabulate(result_recall, floatfmt=\".4f\", headers=(\"model\", 'Recall')))\n",
    "print (tabulate(result_f1, floatfmt=\".4f\", headers=(\"model\", 'F1_Score')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voting Classifer and its performance using k-fold\n",
    "classifier=VotingClassifier(estimators=[    \n",
    "    (\"svc_tfidf\", svc_tfidf),\n",
    "    (\"Percept_tfidf\", percept_tfidf),\n",
    "    (\"etree_tfidf\", etree_tfidf),\n",
    "    (\"rand_tfidf\",rand_tfidf),\n",
    "    (\"etree_w2v\", etree_w2v),\n",
    "    (\"rand_w2v\",rand_w2v),\n",
    "    (\"etree_combo\", etree_combo),\n",
    "    (\"rand_combo\",rand_combo)], voting='hard')\n",
    "\n",
    "result_accuracy = cross_val_score(classifier, X, y, scoring='accuracy', cv=10)\n",
    "result_precision = cross_val_score(classifier, X, y, scoring='precision', cv=10)\n",
    "result_recall = cross_val_score(classifier, X, y, scoring='recall', cv=10)\n",
    "result_f1 = cross_val_score(classifier, X, y, scoring='f1', cv=10)\n",
    "\n",
    "print(result_accuracy.mean())\n",
    "print(result_precision.mean())\n",
    "print(result_recall.mean())\n",
    "print(result_f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model set with Voting Classifier\n",
    "Model_Set_with_voting_clf= [(\"svc_tfidf\", svc_tfidf),\n",
    "    (\"Percept_tfidf\", percept_tfidf),\n",
    "    (\"etree_tfidf\", etree_tfidf),\n",
    "    (\"rand_tfidf\",rand_tfidf),\n",
    "    (\"etree_w2v\", etree_w2v),\n",
    "    (\"rand_w2v\",rand_w2v),\n",
    "    (\"etree_combo\", etree_combo),\n",
    "    (\"rand_combo\",rand_combo),\n",
    "    (\"voting_classifier\",classifier)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of Performance of various classifiers using Stratified Shuffle Split\n",
    "def PerfEval(model, X, y, n):\n",
    "    test_size = 1 - (n / float(len(y)))\n",
    "    scores = []\n",
    "    for train, test in StratifiedShuffleSplit(y, n_iter=10, test_size=test_size):\n",
    "        X_train, X_test = X[train], X[test]\n",
    "        y_train, y_test = y[train], y[test]\n",
    "        scores.append(f1_score(model.fit(X_train, y_train).predict(X_test), y_test)) #For other performance metrics, Change 'f1_score' to 'accuracy_score' or 'precision_score' or 'recall_score'\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting train sizes for Stratified Shuffle Split\n",
    "train_sizes = [10,40,160,640,1000,1400,2500]\n",
    "table = []\n",
    "for name, model in Model_Set_with_voting_clf:\n",
    "    for n in train_sizes:\n",
    "        table.append({'model': name, \n",
    "                      'f1': PerfEval(model, X, y, n), \n",
    "                      'train_size': n})\n",
    "df = pd.DataFrame(table)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting of models trained with varied features by Stratified Shuffle Split\n",
    "plt.figure(figsize=(10, 6))\n",
    "fig = sns.pointplot(x='train_size', y='f1', hue='model', \n",
    "                    data=df[df.model.map(lambda x: x in [\"svc_tfidf\",\n",
    "                                                         \"Percept_tfidf\",\n",
    "                                                         \"etree_tfidf\",\n",
    "                                                         \"rand_tfidf\",\n",
    "                                                         \"etree_w2v\",\n",
    "                                                         \"rand_w2v\",\n",
    "                                                         \"etree_combo\",\n",
    "                                                         \"rand_combo\",\n",
    "                                                         \"voting_classifier\"\n",
    "                                                        ])])\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1)\n",
    "fig.set(xlabel=\"Labeled Training Samples\")\n",
    "fig.set(ylabel=\"F1-Score\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
